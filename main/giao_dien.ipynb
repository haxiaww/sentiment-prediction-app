{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OCckqjxEep19",
        "jPXS9z_rf5um",
        "7US2GtoqgQy5",
        "p30-dt1dkPO-",
        "CL26gCBrlT41",
        "C_-E5Jmqkevp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haxiaww/sentiment-prediction-app/blob/app/giao_dien.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ToeLBe2eGRz",
        "outputId": "8861d85c-fc86-473c-bbc5-962314f8eb2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##fundamentals"
      ],
      "metadata": {
        "id": "AR7LbZhN6Fe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Thư viện\n",
        "import imageio\n",
        "import joblib            as jlb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy             as np\n",
        "import pandas            as pd\n",
        "import pydotplus         as pdp\n",
        "import seaborn           as sns\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn                 import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXYyXVnOeMpf",
        "outputId": "8304761e-cdb6-45b5-f61d-3d304271004b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "punct=string.punctuation"
      ],
      "metadata": {
        "id": "jWdF5G14s8Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove(text):\n",
        "  text=re.sub(r'[0-9]+','',text).lower()#xóa số\n",
        "  text=re.sub(r'(www|http)\\S+', '', text) #xóa URL\n",
        "  text=text.translate(str.maketrans('','',punct)) #xóa punctuation\n",
        "  return text"
      ],
      "metadata": {
        "id": "higzqCsSsas5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "stopword_list=nltk.corpus.stopwords.words('english')\n",
        "stopword_list.remove('no')\n",
        "stopword_list.remove('not')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-fx0fsIsd_Y",
        "outputId": "11cc7422-471b-47a3-c91e-89e8a95a2895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "  return \" \".join([word for word in text.split() if word not in set(stopword_list)])"
      ],
      "metadata": {
        "id": "nfEehg8XshAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def abbreviation(text):\n",
        "  #Điều này có nghĩa là nó coi trích dẫn đơn là một ký tự chữ chứ không phải là\n",
        "  #một ký tự đặc biệt với ý nghĩa thông thường trong biểu thức chính quy\n",
        "  text=re.sub(r'can\\'t','can not',text)\n",
        "  text=re.sub(r'n\\'t','not',text)\n",
        "  text=re.sub(r'\\'m','can not',text)\n",
        "  text=re.sub(r'\\'ll','will',text)\n",
        "  text=re.sub(r'\\'ve','have',text)\n",
        "  text=re.sub(r'\\'t','not',text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "m0Xbx5LQskGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def space(text):\n",
        "  text = re.sub('\\s\\s+',' ',text)\n",
        "  return text #xóa khoảng trắng trùng lắp"
      ],
      "metadata": {
        "id": "knkyqqMFsnFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem_and_lemmatize(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = nltk.word_tokenize(text)\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
        "    return ' '.join(lemmatized_words)"
      ],
      "metadata": {
        "id": "kLm6UJuMtCyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##main interface"
      ],
      "metadata": {
        "id": "57So8DWU6LaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@anvil.server.callable\n",
        "def cleaned_text(text):\n",
        "  text=abbreviation(text)\n",
        "  text=remove(text)\n",
        "  text=remove_stopwords(text)\n",
        "  text=space(text)\n",
        "  text=stem_and_lemmatize(text)\n",
        "  return(text)"
      ],
      "metadata": {
        "id": "brs0LzRpsqMx"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "uplink_key = getpass('Enter your Uplink key: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5hjgvMATG9S",
        "outputId": "a5c77dbf-fb18-40d9-8e18-91dceaa8d761"
      },
      "execution_count": 107,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Uplink key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anvil-uplink"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "X6puRtbTTPWo",
        "outputId": "7c9dfa95-8d89-4cfd-ca12-a7c527805618"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.4.2-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argparse (from anvil-uplink)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.16.0)\n",
            "Collecting ws4py (from anvil-uplink)\n",
            "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45228 sha256=883f3e68b512a24ca3534ccf66c8dd4cd0744b7c520e2f4451d67ce32932b48c\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/7c/ad/d9c746276bf024d44296340869fcb169f1e5d80fb147351a57\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.4.2 argparse-1.4.0 ws4py-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import anvil.server"
      ],
      "metadata": {
        "id": "EbE26g_-TTeC"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anvil.server.connect(uplink_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY6ML65bTVey",
        "outputId": "58b6a012-7bcd-4f5c-f5b1-0a2dd100c7b9"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default Environment\" as SERVER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "9pJzb1VNL5-0"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/My Drive/Colab Notebooks/Data/tf_idf.pkl', 'rb') as f:\n",
        "    tfidf_vectorizer = pickle.load(f)"
      ],
      "metadata": {
        "id": "G313liOBondd"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_model_filepath = '/content/gdrive/My Drive/Colab Notebooks/dl_model.pkl'\n",
        "with open(ann_model_filepath, 'rb') as file:\n",
        "    ann_model = pickle.load(file)\n",
        "log_model_filepath = '/content/gdrive/My Drive/Colab Notebooks/logit_model.pkl'\n",
        "with open(log_model_filepath, 'rb') as file:\n",
        "    log_model = pickle.load(file)\n",
        "tree_model_filepath = '/content/gdrive/My Drive/Colab Notebooks/tree_model.pkl'\n",
        "with open(tree_model_filepath, 'rb') as file:\n",
        "    tree_model = pickle.load(file)"
      ],
      "metadata": {
        "id": "FmHvhf-PovWM"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@anvil.server.callable\n",
        "def predict_sentiment_logistic(input_text):\n",
        "    preprocessed_text = cleaned_text(input_text)\n",
        "    input_vector = tfidf_vectorizer.transform([preprocessed_text]).toarray()\n",
        "    prediction = log_model.predict([input_vector])\n",
        "    if prediction[0] >= 0.5:\n",
        "        sentiment = 'Positive'\n",
        "    else:\n",
        "        sentiment = 'Negative'\n",
        "    res = \"Model Logistic Regression predicted the input text to be: \" + sentiment\n",
        "    return res\n",
        "@anvil.server.callable\n",
        "def predict_sentiment_tree(input_text):\n",
        "    preprocessed_text = cleaned_text(input_text)\n",
        "    input_vector = tfidf_vectorizer.transform([preprocessed_text]).toarray()\n",
        "    prediction = tree_model.predict([input_vector])\n",
        "    if prediction[0] >= 0.5:\n",
        "        sentiment = 'Positive'\n",
        "    else:\n",
        "        sentiment = 'Negative'\n",
        "    res = \"Model Decision Tree predicted the input text to be: \" + sentiment\n",
        "    return res\n",
        "@anvil.server.callable\n",
        "def predict_sentiment_ann(input_text):\n",
        "    preprocessed_text = cleaned_text(input_text)\n",
        "    input_vector = tfidf_vectorizer.transform([preprocessed_text]).toarray()\n",
        "    prediction = ann_model.predict([input_vector])\n",
        "    if prediction[0] >= 0.5:\n",
        "        sentiment = 'Positive'\n",
        "    else:\n",
        "        sentiment = 'Negative'\n",
        "    res = \"Model ANN predicted the input text to be: \" + sentiment\n",
        "    return res"
      ],
      "metadata": {
        "id": "Bbq3-6cbnyI0"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@anvil.server.callable\n",
        "def logistic_predicted_score(input_text):\n",
        "  preprocessed_text = cleaned_text(input_text)\n",
        "  input_vector = tfidf_vectorizer.transform([preprocessed_text]).toarray()\n",
        "  prediction = log_model.predict([input_vector])\n",
        "  res = \"Model Logistic Regression predicted sentiment score: \" + str(prediction[0])\n",
        "  return res\n",
        "@anvil.server.callable\n",
        "def tree_predicted_score(input_text):\n",
        "  preprocessed_text = cleaned_text(input_text)\n",
        "  input_vector = tfidf_vectorizer.transform([preprocessed_text]).toarray()\n",
        "  prediction = tree_model.predict([input_vector])\n",
        "  res = \"Model Decision Tree predicted sentiment score: \" + str(prediction[0])\n",
        "  return res\n",
        "@anvil.server.callable\n",
        "def ann_predicted_score(input_text):\n",
        "  preprocessed_text = cleaned_text(input_text)\n",
        "  input_vector = tfidf_vectorizer.transform([preprocessed_text]).toarray()\n",
        "  prediction = ann_model.predict([input_vector])\n",
        "  res = \"Model ANN predicted sentiment score: \" + str(prediction[0])\n",
        "  return res"
      ],
      "metadata": {
        "id": "5-G7XDXJycHi"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@anvil.server.callable\n",
        "def final_report(input_text):\n",
        "  res1 = logistic_predicted_score(input_text)\n",
        "  res2 = tree_predicted_score(input_text)\n",
        "  res3 = ann_predicted_score(input_text)\n",
        "  res = res1 + '\\n' + res2 + '\\n' + res3\n",
        "  return res"
      ],
      "metadata": {
        "id": "DJBY701RzWZm"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anvil.server.wait_forever()"
      ],
      "metadata": {
        "id": "7Zag-41G6XgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
